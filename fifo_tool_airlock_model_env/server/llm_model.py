from abc import ABC, abstractmethod
import logging
from fifo_tool_airlock_model_env.common.models import InferenceRequestContainerized


logger = logging.getLogger(__name__)

class LLMModel(ABC):
    """
    Abstract base class for model implementations.
    """

    @abstractmethod
    def load_model(self) -> None:
        """
        Load and initialize the model and its dependencies.
        """
        raise NotImplementedError

    @abstractmethod
    def generate(self, request: InferenceRequestContainerized) -> str:
        """
        Generate a response from a list of role-based messages.
        """
        raise NotImplementedError

    def _log_token_stats(self,
                           model_name: str,
                           adapter_name: str | None,
                           input_tokens: int,
                           output_tokens: int,
                           duration: float):
        """
        Log input/output token counts and generation time duration for a given model/adapter.

        Args:
            model_name (str):
                Name of the model

            adapter_name (str | None):
                Optional adapter name

            input_tokens (int):
                Number of tokens in the prompt.

            output_tokens (int):
                Number of tokens generated by the model.

            duration (float):
                Time in seconds taken to generate the response.
        """
        adapter = "[base model]" if adapter_name is None else f"[{adapter_name}]"
        logger.info("📥 %4d tokens in   ➜   📤 %4d tokens out   ⏱️ %.2fs    📦 %s%s",
                    input_tokens, output_tokens, duration, model_name, adapter)
