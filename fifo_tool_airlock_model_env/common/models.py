from __future__ import annotations
from enum import Enum
from pydantic import BaseModel, Field


class Role(str, Enum):
    """
    Role of a message in a conversation.

    Values:
        user (str):
            Input from the end-user.

        assistant (str):
            Response generated by the model.

        system (str):
            Instruction for the model (e.g. behavior setup).

        tool (str):
            Output from a tool/function call.
    """
    user = "user"
    assistant = "assistant"
    system = "system"
    tool = "tool"


class Model(str, Enum):
    """
    Supported model identifiers.

    Values:
        Phi4MiniInstruct (str):
            Text-only instruction-tuned model.

        Phi4MultimodalInstruct (str):
            Image+text capable instruction model.
    """
    Phi4MiniInstruct = "Phi4MiniInstruct"
    Phi4MultimodalInstruct = "Phi4MultimodalInstruct"


class GenerationParameters(BaseModel):
    """
    Optional text generation parameters to control decoding behavior.

    Fields:
        temperature (float | None):
            Sampling temperature (higher = more random).

        top_k (int | None):
            Limits sampling to top-k tokens.

        top_p (float | None):
            Nucleus sampling probability threshold.

        do_sample (bool | None):
            Whether to sample or use greedy decoding.

        max_new_tokens (int | None):
            Maximum number of tokens to generate.

        repetition_penalty (float | None):
            Penalizes repeated tokens.

        presence_penalty (float | None):
            Penalizes tokens already present.

        frequency_penalty (float | None):
            Penalizes frequent tokens.
    """
    temperature: float | None = None
    top_k: int | None = None
    top_p: float | None = None
    do_sample: bool | None = None
    max_new_tokens: int | None = None
    repetition_penalty: float | None = None
    presence_penalty: float | None = None
    frequency_penalty: float | None = None


class Message(BaseModel):
    """
    A single message in a prompt sequence.

    Fields:
        role (Role):
            The speaker identity (e.g. user, assistant).

        content (str):
            The message text content.
    """
    role: Role
    content: str

    @classmethod
    def system(cls, content: str) -> Message:
        """
        Create a system message.

        Args:
            content (str):
                The system prompt content, typically used to define behavior
                or task-specific instructions for the model.

        Returns:
            Message:
                A message with role set to `Role.system`.
        """
        return cls(role=Role.system, content=content)

    @classmethod
    def user(cls, content: str) -> Message:
        """
        Create a user message.

        Args:
            content (str):
                The user input or question for the model.

        Returns:
            Message:
                A message with role set to `Role.user`.
        """
        return cls(role=Role.user, content=content)

    @classmethod
    def assistant(cls, content: str) -> Message:
        """
        Create an assistant message.

        Args:
            content (str):
                The model's response content.

        Returns:
            Message:
                A message with role set to `Role.assistant`.
        """
        return cls(role=Role.assistant, content=content)

    @classmethod
    def tool(cls, content: str) -> Message:
        """
        Create a tool message.

        Args:
            content (str):
                The output of a function/tool invoked by the model.

        Returns:
            Message:
                A message with role set to `Role.tool`.
        """
        return cls(role=Role.tool, content=content)


class InferenceRequest(BaseModel):
    """
    Full request for sending input to a model running in an airlock container.

    This version is visible to SDK users and explicitly includes the target container name.

    Fields:
        model (Model):
            Which model to use (must match loaded config).

        adapter (str | None):
            Optional adapter/fine-tune identifier.

        messages (list[Message]):
            Input message sequence.

        images (list[str] | None):
            Optional list of images to be used for multimodal models.
            Each item must be a base64-encoded image string (no URLs or paths).
            Ignored by text-only models.

        parameters (GenerationParameters):
            Optional generation config. If omitted, defaults to an empty configuration.
            Each field inside is also optional and may be left unset.

        container_name (str):
            Name of the airlock container serving the model.
    """
    model: Model
    adapter: str | None = None
    messages: list[Message]
    images: list[str] | None = None
    parameters: GenerationParameters = Field(default_factory=GenerationParameters)
    container_name: str


class InferenceRequestContainerized(BaseModel):
    """
    Internal version of the request used after container routing.

    This is constructed at the bridge level and not visible to end users or the SDK.

    Fields:
        model (Model):
            Which model to use.

        adapter (str | None):
            Optional adapter name.

        messages (list[Message]):
            Input messages.

        images (list[str] | None):
            Optional list of images to be used for multimodal models.
            Each item must be a base64-encoded image string (no URLs or paths).
            Ignored by text-only models.

        parameters (GenerationParameters):
            Optional generation config. If omitted, defaults to an empty configuration.
            Each field inside is also optional and may be left unset.
    """
    model: Model
    adapter: str | None = None
    messages: list[Message]
    images: list[str] | None = None
    parameters: GenerationParameters = Field(default_factory=GenerationParameters)
